{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Runthrough of model\n",
    "#1) Set + fit the x/ytrain to train model (random forest, regression, etc)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(final_X_train, y_train)\n",
    "#1a) predict model's results using validation values\n",
    "preds_valid = model.predict(final_X_valid)\n",
    "#2) Drop or Impute any Missing/Null values\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0]) \n",
    "#3) If the # of total missing values < 20% of total data, then might be able to impute\n",
    "print(X_train.shape)\n",
    "#4) Use MAE score of Impute/Drop to determine if you want to drop or impute\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "#5) whichever has lower MAE score run it\n",
    "#either impute\n",
    "final_imputer = SimpleImputer(strategy='median')\n",
    "final_X_train = pd.DataFrame(final_imputer.fit_transform(X_train))\n",
    "final_X_valid = pd.DataFrame(final_imputer.transform(X_valid))\n",
    "#or drop\n",
    "missing_cols = [col for col in X_train.columns\n",
    "                if X_train[col].isnull().any()]# Your code here\n",
    "\n",
    "# Fill in the lines below: drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(missing_cols,axis=1)\n",
    "reduced_X_valid = X_valid.drop(missing_cols,axis=1)\n",
    "forest_model = RandomForestRegressor(random_state=0)\n",
    "forest_model.fit(reduced_X_train,train_y)\n",
    "melb_pred = forest_model.predict(reduced_X_valid)\n",
    "print(mean_absolute_error(val_y,melb_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**************************************Missing Values**************************************************\n",
    "#1ST METHOD - DROP Columns with NaN Values - not a great method - loses a lot of info\n",
    "missing_cols = [col for col in X_train.columns\n",
    "               if X_train[col]isnull().any()]\n",
    "reduced_X_train = X_train.drop(missing_cols, axis=1) #MAKE SURE AXIS = 1 - column \n",
    "reduced_X_valid = X_valid.drop(missing_cols, axis=1)\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2ND METHOD - Regression imputation(more advanced) or replace NaN with Mean values (basic) \n",
    "#both ways make no difference once plugged into a model\n",
    "from sklearn.impute import SimpleImputer\n",
    "my_imputer = SimpleImputer()\n",
    "\n",
    "imputed_X_train= pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-5f7a1a96573e>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-5f7a1a96573e>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    X_valid_imputed[col+;was missing'] = X_valid_imputed[col].isnull()\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#3rd METHOD - Imputation while tracking values that were imputed \n",
    "\n",
    "#variables:\n",
    "#imputed X_train plus = the new imputed values\n",
    "#X_train plus = the tracker of the removed/imputed values\n",
    "\n",
    "#use a copy of the X_train/valid data\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_valid.copy()\n",
    "\n",
    "#Make new columns\n",
    "for col in missing_cols:\n",
    "    X_train_plus[col+'was missing']= X_train_imputed[col].isnull()\n",
    "    X_valid_plus[col+'was missing'] = X_valid_imputed[col].isnull()\n",
    "#imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "#Imputation removed columns - replace them\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_train_plus.columns= X_valid_plus.columns\n",
    "\n",
    "print (\"MAE rom Approach 3 (An Extension to Imputation):\")\n",
    "print(score_dataset(imputed_X_train_plus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usually, Imputation > Dropping columns IF # missing values in data set is low\n",
    "#Sometimes, Dropping columns > Imputation (MAE better)\n",
    "#Why? -1) dataset noise 2)imputation not a great match to dataset (imputation = filling in the mean value, but for that specific column of data it makes more sense to set every missing value to a value of 0, the most frequently encountered value.\n",
    "# ex) GarageYrBlt column (which indicates the year that the garage was built). In some cases, a missing value could indicate a house that does not have a garage. \n",
    "#Does it make more sense to fill in the median value along each column in this case? \n",
    "#Or could we get better results by filling in the minimum value along each column? It's not quite clear what's best in this case, but perhaps we can rule out some options immediately - for instance, setting missing values in this column to 0 is likely to yield horrible results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**************************************Categorical Values**************************************************\n",
    "#STEP 0\n",
    "#Get list of the Categorical Variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_col = list(s[s].index)\n",
    "print(\"Categorical Variables\")\n",
    "printï¼ˆobject_col)\n",
    "#1ST METHOD - DROP - only works if they hold no useful info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2ND METHOD - Label Encoding - assign #'s to categorical values\n",
    "# only works with ordinal values (clear ordering/ranking in the values)\n",
    "#ex never(0) < rarely(1) < sometimes (2) < often (3) < always (4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3RD METHOD - One Hot Encoding - assign # to non ordinal categorical values\n",
    "# creates a separate column for each category - 1 for on, 0 for off\n",
    "# not so good once over ~ 15 different categories\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
